{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## airtable_utilites_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas (Man there's some many ways to do this!)\n",
    "- Pull in current house value from ZIllow using Zillow API\n",
    "- Looks like I can automatically pull in Apple health data: https://www.healthexportapp.com/\n",
    "- Could have a personal and profressional dashboard if I run out of space\n",
    "- I would like to make a repo for this.\n",
    "- Is there an airtable app to show a little bit of a table?\n",
    "- Add \"subgoals complete\" to dashboard?\n",
    "- Force tables up to current day (stop at end of quarter?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "jupyter nbconvert --ExecutePreprocessor.timeout=600 --to notebook --execute airtable_utilites_v1.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "from airtable import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S',level='INFO')\n",
    "logger=logging.getLogger(__name__)\n",
    "logger.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "END_OF_PERIOD=pd.datetime.strptime('2021-6-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:49] p5663 {<ipython-input-4-40334cc72b2c>:1} INFO - Connecting to Exercise Log table...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Connecting to Exercise Log table...')\n",
    "a=Airtable('appXxfrycEcPpmzgZ', 'Exercise Log', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:50] p5663 {<ipython-input-5-3292140206b1>:2} INFO - Found 50 exercise logs\n"
     ]
    }
   ],
   "source": [
    "res=a.get_all()\n",
    "logger.info('Found %i exercise logs', len(res))\n",
    "res=[{**r['fields'], **r} for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:50] p5663 {<ipython-input-6-e27dd6a78e81>:1} INFO - Converting to dataframe and resampling...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Converting to dataframe and resampling...')\n",
    "df=pd.DataFrame(res)\n",
    "df.index=pd.DatetimeIndex(df['Date'])\n",
    "\n",
    "df=df.sort_index()\n",
    "df['Type']=[o[0] for o in df['Exercise Type']]\n",
    "dfr=df.resample('D').sum() #Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if datetime.now()>END_OF_PERIOD: end_date=END_OF_PERIOD\n",
    "else: end_date=pd.datetime.now()\n",
    "    \n",
    "# dfr.loc[pd.datetime.strptime('2021-4-20', '%Y-%m-%d')]=0 #Working test case\n",
    "if end_date not in dfr.index: #Do we have data from today?\n",
    "    dfr.loc[end_date]=0 #Add 0s at todays date\n",
    "    dfr=dfr.resample('D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:50] p5663 {<ipython-input-8-2266225b9fc1>:1} INFO - Computing cumulative sums by type...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Computing cumulative sums by type...')\n",
    "\n",
    "for s in df['Type'].unique(): dfr['Volume_'+s]=df[df['Type']==s]['Volume'].resample('D').sum()\n",
    "dfr=dfr.replace(np.NaN, 0)\n",
    "for s in df['Type'].unique(): dfr['Volume_Cumulative_'+s]=dfr['Volume_'+s].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:50] p5663 {<ipython-input-9-ebf85e75d19d>:1} INFO - Connecting to Exercise Analytics table...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Connecting to Exercise Analytics table...')\n",
    "a2=Airtable('appXxfrycEcPpmzgZ', 'Exercise Analytics', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:50] p5663 {<ipython-input-10-ed77463c2acb>:1} INFO - Deleting old Analytics data..\n"
     ]
    }
   ],
   "source": [
    "logger.info('Deleting old Analytics data..')\n",
    "r=a2.get_all()\n",
    "ids=[o['id'] for o in r]\n",
    "res=a2.batch_delete(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:06:59] p5663 {<ipython-input-11-c165ed44ade0>:1} INFO - Uploading new analytics data...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Uploading new analytics data...')\n",
    "l=[]\n",
    "for s in df['Type'].unique():\n",
    "    for d in dfr.index:\n",
    "        l.append({'Date': str(d.date()),\n",
    "                 'Exercise Volume': dfr.loc[d]['Volume_Cumulative_'+s],\n",
    "                 'Exercise Type': s})\n",
    "res=a2.batch_insert(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Metrics \n",
    "\n",
    "- I think the patters are staring to emerge, it's like an outcome/goal, tactics, and leads. \n",
    "- Perhaps I can make a general one of these for any goal??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id='appXxfrycEcPpmzgZ'\n",
    "api_key='' #TODO - put in env\n",
    "src_table_name='Quality & Habits Log'\n",
    "dst_table_name='Quality Analytics'\n",
    "lead_measures=['Mediation', 'Gratitude', 'Affirmations', 'Visualization', 'Reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:1} INFO - Connecting to Quality & Habits Log table...\n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:5} INFO - Found 43 records\n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:8} INFO - Converting to dataframe and resampling...\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:19} INFO - Using todays date 2021-05-09 20:07:08.618818 as end date\n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:22} INFO - No data found from end_date, adding 0 record. \n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:26} INFO - Computing cumulative sums by type...\n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:30} INFO - Connecting to Quality Analytics table...\n",
      "[05-09 20:07:08] p5663 {<ipython-input-13-ca3e6e0fe6a9>:33} INFO - Deleting existing Quality Analytics data..\n",
      "[05-09 20:07:16] p5663 {<ipython-input-13-ca3e6e0fe6a9>:38} INFO - Uploading new analytics data...\n",
      "[05-09 20:07:24] p5663 {<ipython-input-13-ca3e6e0fe6a9>:47} INFO - Completed uploading 220 records. \n"
     ]
    }
   ],
   "source": [
    "logger.info('Connecting to %s table...', src_table_name)\n",
    "a=Airtable(base_id, src_table_name, api_key)\n",
    "\n",
    "res=a.get_all()\n",
    "logger.info('Found %i records', len(res))\n",
    "res=[{**r['fields'], **r} for r in res]\n",
    "\n",
    "logger.info('Converting to dataframe and resampling...')\n",
    "df=pd.DataFrame(res)\n",
    "df.index=pd.DatetimeIndex(df['Date'])\n",
    "df=df.sort_index()\n",
    "dfr=df.resample('D').sum() #Resample\n",
    "\n",
    "if datetime.now()>END_OF_PERIOD: \n",
    "    logger.info('Period has ended, using %s as end date', END_OF_PERIOD)\n",
    "    end_date=END_OF_PERIOD\n",
    "else: \n",
    "    end_date=pd.datetime.now()\n",
    "    logger.info('Using todays date %s as end date', end_date)\n",
    "    \n",
    "if end_date not in dfr.index: #Do we have data from today?\n",
    "    logger.info('No data found from end_date, adding 0 record. ')\n",
    "    dfr.loc[end_date]=0 #Add 0s at todays date\n",
    "    dfr=dfr.resample('D').sum()\n",
    "\n",
    "logger.info('Computing cumulative sums by type...')\n",
    "for s in lead_measures: dfr['Cumulative_'+s]=dfr[s].cumsum()\n",
    "dfr=dfr.replace(np.NaN, 0)\n",
    "\n",
    "logger.info('Connecting to %s table...', dst_table_name)\n",
    "a=Airtable(base_id, dst_table_name, api_key)\n",
    "\n",
    "logger.info('Deleting existing %s data..', dst_table_name)\n",
    "r=a.get_all()\n",
    "ids=[o['id'] for o in r]\n",
    "res=a.batch_delete(ids)\n",
    "\n",
    "logger.info('Uploading new analytics data...')\n",
    "l=[]\n",
    "for s in lead_measures:\n",
    "    for d in dfr.index:\n",
    "        l.append({'Date': str(d.date()),\n",
    "                 'Measure': dfr.loc[d][s],\n",
    "                 'Cumulative Measure': dfr.loc[d]['Cumulative_'+s],\n",
    "                 'Tactic': s})\n",
    "res=a.batch_insert(l)\n",
    "logger.info('Completed uploading %i records. ', len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welch Labs Analytics \n",
    "- There's some subtle differences between all of these, it will be intersting to see if I can unify...\n",
    "- TODO: tease out figures drafted vs completed figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id='appjZFu7NntgaSGMj'\n",
    "api_key='' #TODO - put in env\n",
    "src_table_names=['References [R]','Correspondence [C]','Figures [F]','Style Examples']\n",
    "views=['CV Book','CV Book','CV Book','CV Book']\n",
    "dst_table_name='Research Analytics'\n",
    "# lead_measures=['References Collected', 'Correspondances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:07:24] p5663 {<ipython-input-15-ab11ab11b01b>:3} INFO - Connecting to References [R] table...\n",
      "[05-09 20:07:24] p5663 {<ipython-input-15-ab11ab11b01b>:7} INFO - Found 46 records\n",
      "[05-09 20:07:24] p5663 {<ipython-input-15-ab11ab11b01b>:11} INFO - Converting to dataframe and resampling...\n",
      "[05-09 20:07:24] p5663 {<ipython-input-15-ab11ab11b01b>:3} INFO - Connecting to Correspondence [C] table...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:7} INFO - Found 7 records\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:11} INFO - Converting to dataframe and resampling...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:3} INFO - Connecting to Figures [F] table...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:7} INFO - Found 8 records\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:11} INFO - Converting to dataframe and resampling...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:3} INFO - Connecting to Style Examples table...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:7} INFO - Found 15 records\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:11} INFO - Converting to dataframe and resampling...\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:26} INFO - Using todays date 2021-05-10 00:07:25.876984+00:00 as end date\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:29} INFO - No data found from end_date, adding 0 record. \n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:33} INFO - Computing cumulative sum...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:39} INFO - Connecting to Research Analytics table...\n",
      "[05-09 20:07:25] p5663 {<ipython-input-15-ab11ab11b01b>:42} INFO - Deleting existing Research Analytics data..\n",
      "[05-09 20:07:31] p5663 {<ipython-input-15-ab11ab11b01b>:47} INFO - Uploading new analytics data...\n",
      "[05-09 20:07:36] p5663 {<ipython-input-15-ab11ab11b01b>:56} INFO - Completed uploading 136 records. \n"
     ]
    }
   ],
   "source": [
    "dfrs=[]\n",
    "for src_table_name,view in zip(src_table_names, views):\n",
    "    logger.info('Connecting to %s table...', src_table_name)\n",
    "    a=Airtable(base_id, src_table_name, api_key)\n",
    "\n",
    "    res=a.get_all(view=view)\n",
    "    logger.info('Found %i records', len(res))\n",
    "    if len(res)==0: continue\n",
    "    res=[{'id':r['id'], 'createdTime':r['createdTime'], src_table_name:1} for r in res]\n",
    "\n",
    "    logger.info('Converting to dataframe and resampling...')\n",
    "    df=pd.DataFrame(res)\n",
    "    df.index=pd.DatetimeIndex(df['createdTime'])\n",
    "    dfr=df.resample('D').sum() #Resample\n",
    "    dfrs.append(dfr)\n",
    "\n",
    "dfrs=pd.concat(dfrs, sort=False)\n",
    "dfrs=dfrs.resample('D').sum() #Handle 2:1 case\n",
    "dfrs=dfrs.sort_index()\n",
    "\n",
    "if datetime.now()>END_OF_PERIOD: \n",
    "    logger.info('Period has ended, using %s as end date', END_OF_PERIOD)\n",
    "    end_date=END_OF_PERIOD\n",
    "else: \n",
    "    end_date=pd.datetime.now(pytz.utc)\n",
    "    logger.info('Using todays date %s as end date', end_date)\n",
    "    \n",
    "if end_date not in dfr.index: #Do we have data from today?\n",
    "    logger.info('No data found from end_date, adding 0 record. ')\n",
    "    dfrs.loc[end_date]=0 #Add 0s at todays date\n",
    "    dfrs=dfrs.resample('D').sum()\n",
    "\n",
    "logger.info('Computing cumulative sum...')\n",
    "dfrs=dfrs.replace(np.NaN, 0) \n",
    "for src_table_name in src_table_names: dfrs['Cumulative ' + src_table_name]=dfrs[src_table_name].cumsum()\n",
    "dfrs=dfrs.replace(np.NaN, 0) \n",
    "\n",
    "    \n",
    "logger.info('Connecting to %s table...', dst_table_name)\n",
    "a=Airtable(base_id, dst_table_name, api_key)\n",
    "\n",
    "logger.info('Deleting existing %s data..', dst_table_name)\n",
    "r=a.get_all()\n",
    "ids=[o['id'] for o in r]\n",
    "res=a.batch_delete(ids)\n",
    "\n",
    "logger.info('Uploading new analytics data...')\n",
    "l=[]\n",
    "for src_table_name in src_table_names:\n",
    "    for d in dfrs.index:\n",
    "        l.append({'Date': str(d.date()),\n",
    "                 'Measure': dfrs.loc[d][src_table_name],\n",
    "                 'Cumulative Measure': dfrs.loc[d]['Cumulative ' + src_table_name],\n",
    "                 'Tactic': src_table_name})\n",
    "res=a.batch_insert(l)\n",
    "logger.info('Completed uploading %i records. ', len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welch Labs Writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id='appjZFu7NntgaSGMj'\n",
    "api_key='' #TODO - put in env\n",
    "src_table_name='Writing Log'\n",
    "dst_table_name='Writing Analytics'\n",
    "lead_measures=['Words Drafted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:1} INFO - Connecting to Writing Log table...\n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:5} INFO - Found 18 records\n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:8} INFO - Converting to dataframe and resampling...\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:19} INFO - Using todays date 2021-05-09 20:07:36.813470 as end date\n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:22} INFO - No data found from end_date, adding 0 record. \n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:28} INFO - Computing cumulative sums by type...\n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:32} INFO - Connecting to Writing Analytics table...\n",
      "[05-09 20:07:36] p5663 {<ipython-input-17-927b06bb3d86>:35} INFO - Deleting existing Writing Analytics data..\n",
      "[05-09 20:07:38] p5663 {<ipython-input-17-927b06bb3d86>:40} INFO - Uploading new analytics data...\n",
      "[05-09 20:07:39] p5663 {<ipython-input-17-927b06bb3d86>:49} INFO - Completed uploading 36 records. \n"
     ]
    }
   ],
   "source": [
    "logger.info('Connecting to %s table...', src_table_name)\n",
    "a=Airtable(base_id, src_table_name, api_key)\n",
    "\n",
    "res=a.get_all()\n",
    "logger.info('Found %i records', len(res))\n",
    "res=[{**r['fields'], **r} for r in res]\n",
    "\n",
    "logger.info('Converting to dataframe and resampling...')\n",
    "df=pd.DataFrame(res)\n",
    "df.index=pd.DatetimeIndex(df['Date'])\n",
    "df=df.sort_index()\n",
    "dfr=df.resample('D').sum() #Resample\n",
    "\n",
    "if datetime.now()>END_OF_PERIOD: \n",
    "    logger.info('Period has ended, using %s as end date', END_OF_PERIOD)\n",
    "    end_date=END_OF_PERIOD\n",
    "else: \n",
    "    end_date=pd.datetime.now()\n",
    "    logger.info('Using todays date %s as end date', end_date)\n",
    "    \n",
    "if end_date not in dfr.index: #Do we have data from today?\n",
    "    logger.info('No data found from end_date, adding 0 record. ')\n",
    "    dfr.loc[end_date]=0 #Add 0s at todays date\n",
    "    dfr=dfr.resample('D').sum()\n",
    "    \n",
    "dfr=dfr.replace(0, np.nan).ffill() #Metric is already cumulative!\n",
    "\n",
    "logger.info('Computing cumulative sums by type...')\n",
    "for s in lead_measures: dfr['Cumulative_'+s]=dfr[s] #.cumsum()\n",
    "dfr=dfr.replace(np.NaN, 0)\n",
    "\n",
    "logger.info('Connecting to %s table...', dst_table_name)\n",
    "a=Airtable(base_id, dst_table_name, api_key)\n",
    "\n",
    "logger.info('Deleting existing %s data..', dst_table_name)\n",
    "r=a.get_all()\n",
    "ids=[o['id'] for o in r]\n",
    "res=a.batch_delete(ids)\n",
    "\n",
    "logger.info('Uploading new analytics data...')\n",
    "l=[]\n",
    "for s in lead_measures:\n",
    "    for d in dfr.index:\n",
    "        l.append({'Date': str(d.date()),\n",
    "                 'Measure': float(dfr.loc[d][s]),\n",
    "                 'Cumulative Measure': float(dfr.loc[d]['Cumulative_'+s]),\n",
    "                 'Tactic': s})\n",
    "res=a.batch_insert(l)\n",
    "logger.info('Completed uploading %i records. ', len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satisfaction & Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id='appXxfrycEcPpmzgZ'\n",
    "api_key='' #TODO - put in env\n",
    "src_table_name='Quality & Habits Log'\n",
    "dst_table_name='Quality Analytics 2'\n",
    "measures=['Satisfaction', 'Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 20:07:39] p5663 {<ipython-input-19-ee9662896fda>:1} INFO - Connecting to Quality & Habits Log table...\n",
      "[05-09 20:07:40] p5663 {<ipython-input-19-ee9662896fda>:5} INFO - Found 43 records\n",
      "[05-09 20:07:40] p5663 {<ipython-input-19-ee9662896fda>:8} INFO - Converting to dataframe and resampling...\n",
      "[05-09 20:07:40] p5663 {<ipython-input-19-ee9662896fda>:14} INFO - Connecting to Quality Analytics 2 table...\n",
      "[05-09 20:07:40] p5663 {<ipython-input-19-ee9662896fda>:17} INFO - Deleting existing Quality Analytics 2 data..\n",
      "[05-09 20:07:43] p5663 {<ipython-input-19-ee9662896fda>:22} INFO - Uploading new analytics data...\n",
      "[05-09 20:07:45] p5663 {<ipython-input-19-ee9662896fda>:31} INFO - Completed uploading 70 records. \n"
     ]
    }
   ],
   "source": [
    "logger.info('Connecting to %s table...', src_table_name)\n",
    "a=Airtable(base_id, src_table_name, api_key)\n",
    "\n",
    "res=a.get_all()\n",
    "logger.info('Found %i records', len(res))\n",
    "res=[{**r['fields'], **r} for r in res]\n",
    "\n",
    "logger.info('Converting to dataframe and resampling...')\n",
    "df=pd.DataFrame(res)\n",
    "df.index=pd.DatetimeIndex(df['Date'])\n",
    "df=df.sort_index()\n",
    "dfr=df.resample('D').mean() #Resample\n",
    "\n",
    "logger.info('Connecting to %s table...', dst_table_name)\n",
    "a=Airtable(base_id, dst_table_name, api_key)\n",
    "\n",
    "logger.info('Deleting existing %s data..', dst_table_name)\n",
    "r=a.get_all()\n",
    "ids=[o['id'] for o in r]\n",
    "res=a.batch_delete(ids)\n",
    "\n",
    "logger.info('Uploading new analytics data...')\n",
    "l=[]\n",
    "for s in measures:\n",
    "    for d in dfr.index:\n",
    "        if np.isnan(dfr.loc[d][s]): continue\n",
    "        l.append({'Date': str(d.date()),\n",
    "                 'Measure': dfr.loc[d][s],\n",
    "                 'Metric': s})\n",
    "res=a.batch_insert(l)\n",
    "logger.info('Completed uploading %i records. ', len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Writing File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_id='appjZFu7NntgaSGMj'\n",
    "api_key='' #TODO - put in env\n",
    "src_table_name='Writing Log'\n",
    "writing_file='/Users/stephenwelch/Dropbox (Personal)/writing/Computer Vision Book.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-09 21:12:53] p6059 {<ipython-input-5-16d1bdeeb8c8>:1} INFO - Connecting to Writing Log table...\n",
      "[05-09 21:12:53] p6059 {<ipython-input-5-16d1bdeeb8c8>:5} INFO - Found 19 records\n",
      "[05-09 21:12:53] p6059 {<ipython-input-5-16d1bdeeb8c8>:12} INFO - Found Record recgclbuwx956IUFQ from todays date 2021-05-09, deleting...\n",
      "[05-09 21:12:54] p6059 {<ipython-input-5-16d1bdeeb8c8>:15} INFO - Opening /Users/stephenwelch/Dropbox (Personal)/writing/Computer Vision Book.md\n",
      "[05-09 21:12:54] p6059 {<ipython-input-5-16d1bdeeb8c8>:21} INFO - Computed 2234 words drafted\n",
      "[05-09 21:12:54] p6059 {<ipython-input-5-16d1bdeeb8c8>:23} INFO - Uploading new record...\n"
     ]
    }
   ],
   "source": [
    "logger.info('Connecting to %s table...', src_table_name)\n",
    "a=Airtable(base_id, src_table_name, api_key)\n",
    "\n",
    "res=a.get_all()\n",
    "logger.info('Found %i records', len(res))\n",
    "res=[{**r['fields'], **r} for r in res]\n",
    "\n",
    "dt=datetime.strftime(datetime.now(), '%Y-%m-%d')\n",
    "\n",
    "for r in res: \n",
    "    if r['Date']==dt:\n",
    "        logger.info('Found Record %s from todays date %s, deleting...', r['id'], r['Date'])\n",
    "        a.delete(r['id'])\n",
    "        \n",
    "logger.info('Opening %s', writing_file)\n",
    "with open(writing_file, 'r') as f:\n",
    "    t=f.read()\n",
    "    \n",
    "main_text=t.split('The End.')[0]\n",
    "words_drafted=len(main_text.replace('\\n', '').split(' '))\n",
    "logger.info('Computed %i words drafted', words_drafted)\n",
    "\n",
    "logger.info('Uploading new record...')\n",
    "new_record={'Date':dt, 'Words Drafted': words_drafted, 'Project': 'CV Book', 'Full Text': t}\n",
    "res=a.insert(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
